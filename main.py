# Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ú©Ø¯ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø³Øª - Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ù…Ø¯Ù„ Ø±Ø§ÛŒÚ¯Ø§Ù† Mistral
import os
import requests
import asyncio
from dotenv import load_dotenv
from duckduckgo_search import DDGS
from telegram import Bot

# Ù…ÙˆØ¶ÙˆØ¹ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø¢Ù† ØªØ­Ù‚ÛŒÙ‚ Ú©Ù†Ø¯
RESEARCH_TOPIC = "Ø§Ø®Ø¨Ø§Ø± Ø±ÙˆØ² Ø§ÛŒØ±Ø§Ù†"

# --- Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø§Ø² HuggingFace (Ù¾Ù„Ù† Ø±Ø§ÛŒÚ¯Ø§Ù†) ---
# Ø¨Ø±Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ
SUMMARIZER_MODEL_HF = "facebook/bart-large-cnn"
# <<< Ø§ØµÙ„Ø§Ø­ Ø´Ø¯: Ù…Ø¯Ù„ Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ùˆ ÙˆÛŒØ±Ø§Ø³ØªØ§Ø± Ø¨Ù‡ Mistral ØªØºÛŒÛŒØ± Ú©Ø±Ø¯
# Ø¨Ø±Ø§ÛŒ Ù†ÙˆØ´ØªÙ† Ùˆ ÙˆÛŒØ±Ø§ÛŒØ´ Ù…ØªÙ† (ÛŒÚ© Ù…Ø¯Ù„ Ø¨Ø³ÛŒØ§Ø± Ù‚ÙˆÛŒ Ùˆ Ø¯Ø± Ø¯Ø³ØªØ±Ø³)
GENERATIVE_MODEL_HF = "mistralai/Mistral-7B-Instruct-v0.2"


# Ø®ÙˆØ§Ù†Ø¯Ù† Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API Ø§Ø² Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHANNEL_ID = os.getenv("TELEGRAM_CHANNEL_ID")
HUGGINGFACE_API_TOKEN = os.getenv("HUGGINGFACE_API_TOKEN")

def research(topic: str, num_results: int = 5) -> str:
    print(f"ğŸ•µï¸  Ù…Ø§Ù…ÙˆØ± Ù…Ø­Ù‚Ù‚: Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ù…ÙˆØ±Ø¯ '{topic}'...")
    try:
        with DDGS() as ddgs:
            results = [r for r in ddgs.text(topic, max_results=num_results, region='wt-wt')]
            content = " ".join([res.get('body', '') for res in results])
            print("âœ… ØªØ­Ù‚ÛŒÙ‚ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
            return content
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø­ÛŒÙ† Ø¬Ø³ØªØ¬Ùˆ: {e}")
        return ""

def call_huggingface_model(model_name: str, prompt: str) -> str:
    """ÛŒÚ© Ù…Ø¯Ù„ Ø±Ø§ Ø§Ø² Ø·Ø±ÛŒÙ‚ Hugging Face API ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    print(f"ğŸ¤— Ø¯Ø± Ø­Ø§Ù„ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…Ø¯Ù„ Hugging Face: {model_name}...")
    api_url = f"https://api-inference.huggingface.co/models/{model_name}"
    headers = {"Authorization": f"Bearer {HUGGINGFACE_API_TOKEN}"}
    
    try:
        # Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„ÙØŒ ÙØ±Ù…Øª payload Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú©Ù…ÛŒ Ù…ØªÙØ§ÙˆØª Ø¨Ø§Ø´Ø¯
        if "bart-large-cnn" in model_name:
             payload = {"inputs": prompt, "options": {"wait_for_model": True}}
        else:
             # Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ù…Ø«Ù„ Mistral
             payload = {"inputs": prompt, "options": {"wait_for_model": True}, "parameters": {"return_full_text": False, "max_new_tokens": 1024}}

        response = requests.post(api_url, headers=headers, json=payload, timeout=120) # Ø§ÙØ²Ø§ÛŒØ´ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±
        response.raise_for_status() # Ø§ÛŒÙ† Ø®Ø· Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ Ø®Ø·Ø§ØŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±Ø§ Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒÚ©Ù†Ø¯
        data = response.json()
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙØ±Ù…Øª Ù¾Ø§Ø³Ø® Ù…Ø¯Ù„
        if isinstance(data, list) and data:
            if "summary_text" in data[0]:
                generated_text = data[0]['summary_text']
            elif "generated_text" in data[0]:
                generated_text = data[0]['generated_text']
            else:
                generated_text = str(data)
        else:
            generated_text = "Ù¾Ø§Ø³Ø®ÛŒ Ø§Ø² Ù…Ø¯Ù„ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯."

        print("âœ… Ù¾Ø§Ø³Ø® Ø§Ø² Hugging Face Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯.")
        return generated_text
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ÛŒ Hugging Face: {e}")
        return f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ù…Ø¯Ù„ {model_name}"


async def send_to_telegram(message: str):
    print("ğŸ“¤ Ù…Ø§Ù…ÙˆØ± Ù†Ø§Ø´Ø±: Ø¯Ø± Ø­Ø§Ù„ Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…...")
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHANNEL_ID:
        print("âŒ ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª ÛŒØ§ Ø´Ù†Ø§Ø³Ù‡ Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        return
    try:
        bot = Bot(token=TELEGRAM_BOT_TOKEN)
        await bot.send_message(chat_id=TELEGRAM_CHANNEL_ID, text=message, parse_mode='Markdown')
        print("âœ… Ù¾Ø³Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ù…Ù†ØªØ´Ø± Ø´Ø¯!")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…: {e}")

async def main():
    search_results = research(RESEARCH_TOPIC)
    if not search_results:
        print("ØªØ­Ù‚ÛŒÙ‚ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…ØªÙˆÙ‚Ù Ø´Ø¯.")
        return
        
    summary = call_huggingface_model(SUMMARIZER_MODEL_HF, search_results[:3000]) # Ú©Ø§Ù‡Ø´ Ø­Ø¬Ù… Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø¨ÛŒØ´ØªØ±

    writer_prompt = f"You are an expert technology and news writer in Persian. Write a clear, engaging, and accurate post for a Telegram channel about '{RESEARCH_TOPIC}' based on the following summary. Use short paragraphs and simple language. The output must be only the final Persian text of the post.\n\nSummary:\n{summary}"
    initial_post = call_huggingface_model(GENERATIVE_MODEL_HF, writer_prompt)

    editor_prompt = f"You are a strict Persian editor. Review and polish the following text. Make it more fluent and correct any grammatical or factual errors. Your output must be only the final, ready-to-publish Persian text.\n\nText to edit:\n{initial_post}"
    final_post = call_huggingface_model(GENERATIVE_MODEL_HF, editor_prompt)

    final_telegram_message = f"**{RESEARCH_TOPIC}**\n\n{final_post}\n\n#Ù‡ÙˆØ´_Ù…ØµÙ†ÙˆØ¹ÛŒ #Ø®Ø¨Ø± #Ø§ÛŒØ±Ø§Ù†"
    await send_to_telegram(final_telegram_message)

if __name__ == "__main__":
    asyncio.run(main())
